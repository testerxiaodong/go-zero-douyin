### 项目开发环境
- Go语言版本：Go1.19 -> Go1.21.1(最近升级了版本)
- 操作系统：Mac(M1) docker-compose容器适用ARM架构，架构不一致请自行找适合自己架构的镜像

### 创建数据库
项目依赖两个数据库：
- go_zero_douyin(项目数据持久化)
- gorse(推荐系统依赖的数据)
两个数据库的sql文件在/deploy/sql目录下，请手动创建数据库并导入sql文件

### 创建容器
首先需要更改许多依赖的ip地址，请把项目中依赖的ip地址改成自行的依赖。再有就是阿里云OSS的AccessKey
```shell
docker-compose up -d
```

### 创建kafka的topic
主要是两个topic：
- 日志收集topic：douyin-log
- 视频点赞异步处理topic：video-like-topic
```shell
docker exec -it kafka /bin/sh
cd /opt/kafka/bin/
./kafka-topics.sh --create --zookeeper zookeeper:2181 --replication-factor 1 -partitions 1 --topic douyin-log
./kafka-topics.sh --create --zookeeper zookeeper:2181 --replication-factor 1 -partitions 1 --topic video-like-topic

# 重启filebeat和go-stash容器
docker restart filebeat go-stash
```

### 创建elasticsearch索引
两个索引：
- 用户信息索引：用于用户搜索
- 视频信息索引：用户视频搜索
```shell
# es分词器

# 创建目录
docker exec -it elasticsearch /bin/bash
mkdir plugins/ik plugins/pinyin
exit

# 拷贝分词器插件到es
docker cp ./deploy/elasticsearch/plugins/elasticsearch-analysis-ik-7.17.7.zip elasticsearch:/usr/share/elasticsearch/plugins/ik
docker cp ./deploy/elasticsearch/plugins/elasticsearch-analysis-pinyin-7.17.7.zip elasticsearch:/usr/share/elasticsearch/plugins/pinyin

# 配置插件
docker exec -it elasticsearch /bin/bash
cd plugins/ik
unzip elasticsearch-analysis-ik-7.17.7.zip
sed -i 's/elasticsearch\.version=7\.17\.7/elasticsearch\.version=7\.17\.13/' plugin-descriptor.properties
cd ../pinyin
unzip elasticsearch-analysis-pinyin-7.17.7.zip
sed -i 's/elasticsearch\.version=7\.17\.7/elasticsearch\.version=7\.17\.13/' plugin-descriptor.properties
exit

# 重启容器
docker restart elasticsearch
```
kibana控制台创建索引
```
# 创建用户索引
PUT user
{
  "settings": {
    "analysis": {
      "analyzer": {
        "text_analyzer": {
          "tokenizer": "ik_max_word",
          "filter": "py"
        },
        "completion_analyzer": {
          "tokenizer": "keyword",
          "filter": "py"
        }
      },
      "filter": {
        "py": {
          "type": "pinyin",
          "keep_full_pinyin": false,
          "keep_joined_full_pinyin": true,
          "keep_original": true,
          "limit_first_letter_length" : 16,
          "remove_duplicated_term" : true,
          "none_chinese_pinyin_tokenize": false
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "id": {
        "type": "keyword"
      },
      "username": {
        "type": "text",
        "analyzer": "text_analyzer",
        "search_analyzer": "ik_max_word"
      },
      "follower_count": {
        "type": "integer"
      },
      "follow_count": {
        "type": "integer"
      },
      "suggestion": {
        "type": "completion",
        "analyzer": "completion_analyzer"
      },
      "create_time": {
        "type": "date",
        "format": "yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis"
      },
      "update_time": {
        "type": "date",
        "format": "yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis"
      },
      "version": {
        "type": "long"
      }
    }
  }
}

# 创建视频信息文档
PUT video
{
  "settings": {
    "analysis": {
      "analyzer": {
        "text_analyzer": {
          "tokenizer": "ik_max_word",
          "filter": "py"
        },
        "completion_analyzer": {
          "tokenizer": "keyword",
          "filter": "py"
        }
      },
      "filter": {
        "py": {
          "type": "pinyin",
          "keep_full_pinyin": false,
          "keep_joined_full_pinyin": true,
          "keep_original": true,
          "limit_first_letter_length" : 16,
          "remove_duplicated_term" : true,
          "none_chinese_pinyin_tokenize": false
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "id": {
        "type": "keyword"
      },
      "title": {
        "type": "text",
        "analyzer": "text_analyzer",
        "search_analyzer": "ik_max_word"
      },
      "section_id": {
        "type": "keyword"
      },
      "tag_ids": {
        "type": "keyword"
      },
      "owner_id": {
        "type": "keyword"
      },
      "owner_name": {
        "type": "keyword"
      },
      "play_url": {
        "type": "keyword"
      },
      "cover_url": {
        "type": "keyword"
      },
      "comment_count": {
        "type": "long"
      },
      "like_count": {
        "type": "long"
      },
      "create_time": {
        "type": "date",
        "format": "yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis"
      },
      "update_time": {
        "type": "date",
        "format": "yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis"
      },
      "suggestion": {
        "type": "completion",
        "analyzer": "completion_analyzer"
      },
      "version": {
        "type": "long"
      }
    }
  }
}
```

### 配置flink-cdc
项目需要同步mysql数据到es用来搜索，也需要同步mysql数据到mysql(Gorse的数据库)用来做个性化推荐。因此需要三个连接器
- flink-connector-jdbc-3.1.1-1.17.jar
- flink-sql-connector-elasticsearch7-3.0.1-1.17.jar
- flink-sql-connector-mysql-cdc-2.4.1.jar

```shell
拷贝连接器到taskmanager
docker cp ./deploy/flink/connector/flink-connector-jdbc-3.1.1-1.17.jar taskmanager:/opt/flink/lib
docker cp ./deploy/flink/connector/flink-sql-connector-elasticsearch7-3.0.1-1.17.jar taskmanager:/opt/flink/lib
docker cp ./deploy/flink/connector/flink-sql-connector-mysql-cdc-2.4.1.jar taskmanager:/opt/flink/lib
docker restart taskmanager
```

运行flink task，sql文件在/deploy/sql目录下。
